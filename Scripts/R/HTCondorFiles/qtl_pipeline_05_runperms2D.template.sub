# Specify the HTCondor Universe (vanilla is the default and is used
#  for almost all jobs), the desired name of the HTCondor log file,
#  and the desired name of the standard error file.  
#  Wherever you see $(Cluster), HTCondor will insert the queue number
#  assigned to this set of jobs at the time of submission.
universe = vanilla
#Use InitialDir to generate a subset of directories 
InitialDir = $(Process)
executable = ../qtl_pipeline_05_runperms2D.sh
arguments = $(Process) input.seed input.nperms input.model input.trait input.qtlmethod R{R_VERSION}.tar.gz packages-R{R_VERSION}.tar.gz

output = qtl_pipeline_05_runperms2D.out
error = qtl_pipeline_05_runperms2D.err
log = qtl_pipeline_05_runperms2D.log

requirements = (OpSysMajorVer =?= 8)

# Specify that HTCondor should transfer files to and from the
#  computer where each job runs. The last of these lines *would* be
#  used if there were any other files needed for the executable to run.
should_transfer_files = YES
when_to_transfer_output = ON_EXIT
#The following will be modified by a script to include the correct version of R
transfer_input_files=http://proxy.chtc.wisc.edu/SQUID/chtc/el8/R{R_VERSION}.tar.gz,input.seed,input.nperms,input.model,input.trait,input.qtlmethod,../cross.rds,../../qtl_pipeline_05_runperms2D.R,../../packages-R{R_VERSION}.tar.gz
transfer_output_files = operms.2D.$(Process).rds
# Tell HTCondor what amount of compute resources
#  each job will need on the computer where it runs.
request_cpus = 1
request_memory = 2GB 
request_disk = 500MB
#
# Tell HTCondor to run <num> instances of our job:
#Note: The makefile will automatically update this file per the configuration specified
queue 1
