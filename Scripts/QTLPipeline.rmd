---
title: "QTL Pipeline"
author: "Andrew Maule"
date: "3/24/2021"
output: html_document
params:
  install_deps: FALSE #Whether to install dependencies
  clean_traits: FALSE #Whether to run the code to clean up the trait data: Remove outliers, etc
  workflow: 9
  sandbox: sandbox #Name of folder to place circos files needed to render QTL circos plots.
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, include=TRUE, message=FALSE);
workflow  = paste0("../../Workflows/",params$workflow);
rRoot     = paste0(getwd(),"/R")
# Set environment variables that will be available for bash scripts (Make invocation)
Sys.setenv(WORKFLOW=workflow)
Sys.setenv(SANDBOX=params$sandbox)
```

```{r imports, include=FALSE}
setwd(rRoot)
library(tidyverse)
library(ggcorrplot)
source("usefulFunctions.R")
```

```{r deps, include=FALSE}
setwd(rRoot)
source('packagedeps.R', echo=TRUE)
```

## QTL Analysis Pipeline for CNJ02/CNJ04 Upright Data

This code represents the full pipeline for mapping QTLs in two half-sib populations, CNJ02 (Mullica Queen x Crimson Queen, n = 168) and CNJ04 (Mullica Queen x Stevens reciprocal cross, n = 72).

Most of this functionality was originally written in RScript and invoked through \*nix Makefiles. The core functionality will continue to be implemented in the RScript code, but the pipeline flow will be documented and executed through this document, where possible. The only code that will continue to be run through \*nix Makefiles is that which relates to running permutations on the [University of Wisconsin-Madison Center for High-Throughput Computing HTCondor](https://chtc.cs.wisc.edu/) system.

------------------------------------------------------------------------

## Phenotype Data Assesment and Cleaning

This code reads in the collated/combined phenotypic data for both populations, assesses inconsistencies in data, and uses linear models to aid in trimming outliers.

***NOTE: The following code only needs to be run once, unless the underlying code is changed.***

```{r test-code, eval=params$clean_traits}
setwd(rRoot);
source('analyze_remove_outliers.R', echo=TRUE);
```

------------------------------------------------------------------------

## Calculate Upright Means Within Years

```{r means}
setwd(rRoot);
source('qtl_pipeline_00_1_means.R');
```

## Merge Upright and Plot Datasets

### Read in Plot Data, Merge Datasets, and Define Correlation Plot Functions

```{r plotdata-corrs-function, include=TRUE, echo=TRUE}
col1            <- colorRampPalette(c("blue", "white", "red")) 

setwd(rRoot)
cnj02_pdata.tb  <- read_csv(pheno_dpath2fpath("PlotData/CNJ02_PlotData.csv"))
cnj04_pdata.tb  <- read_csv(pheno_dpath2fpath("PlotData/CNJ04_PlotData.csv"))
#Copy Stevens and Mullica Queen entries to CNJ04 dataset, since they are only in CNJ02 datasets
cnj04_pdata.parents.tb <- cnj02_pdata.tb %>% filter(grepl("(Mullica_Queen)|(Stevens)", accession_name, perl=TRUE))
cnj04_pdata.tb <- cnj04_pdata.tb %>% bind_rows(cnj04_pdata.parents.tb)

#Merge the upright data with the plot data.  Pivot the months wider in the plot dataset.
cnj02.merged.tb <- cnjpop.pheno.p2.means.df %>% 
                    full_join(cnj02_pdata.tb %>% pivot_wider(names_from=month, values_from=TY:PAC), by=c("accession_name", "row", "column", "year"))
cnj04.merged.tb <- cnjpop.pheno.p1.means.df %>% 
                    full_join(cnj04_pdata.tb %>% pivot_wider(names_from=month, values_from=TY:PAC), by=c("accession_name", "row", "column", "year"))
#Save the merged data
write_csv(cnj02.merged.tb, file=pheno_dpath2fpath("MergedData/CNJ02_PlotData.csv"))
write_csv(cnj04.merged.tb, file=pheno_dpath2fpath("MergedData/CNJ04_PlotData.csv"))

#Merge the upright data with the plot data.  Average the months in plot dataset.
cnj02_pdata.mmeans.tb   <- cnj02_pdata.tb %>% 
                            group_by(accession_name, row, column, year) %>%
                            summarise(across(.cols=TY:PAC, mean)) %>%
                            ungroup() 
cnj02.merged.mmeans.tb  <- cnjpop.pheno.p2.means.df %>%
                            full_join(cnj02_pdata.mmeans.tb, by=c("accession_name", "row", "column", "year"))
cnj04_pdata.mmeans.tb   <- cnj04_pdata.tb %>% 
                            group_by(accession_name, row, column, year) %>%
                            summarise(across(.cols=TY:PAC, mean)) %>%
                            ungroup() 
cnj04.merged.mmeans.tb  <- cnjpop.pheno.p1.means.df %>%
                            full_join(cnj04_pdata.mmeans.tb, by=c("accession_name", "row", "column", "year"))
#Save the merged data
write_csv(cnj02.merged.mmeans.tb, file=pheno_dpath2fpath("MergedData/CNJ02_PlotData.mmeans.csv"))
write_csv(cnj04.merged.mmeans.tb, file=pheno_dpath2fpath("MergedData/CNJ04_PlotData.mmeans.csv"))

gencorrplot <- function(data.tb, filename, width=1280, height=1024, method="square", type="lower", diag=FALSE, ...) {
  png(filename=filename, bg="transparent", width=width, height=height, units='px')
  corr.tb <- cor(data.tb, use="pairwise.complete.obs")
  pvals <- ggcorrplot::cor_pmat(data.tb)
  corrplot(corr.tb, p.mat=pvals, method=method, type=type, order="hclust", insig="blank", tl.col="black", diag=diag, col=col1(100), ...)
  dev.off()
}

gencorrplot.mixed <- function(data.tb, filename, width=1280, height=1024, lower="square", upper="number", ...) {
  png(filename=filename, bg="transparent", width=width, height=height, units='px')
  corr.tb <- cor(data.tb, use="pairwise.complete.obs")
  pvals <- ggcorrplot::cor_pmat(data.tb)
  corrplot.mixed(corr.tb, p.mat=pvals, lower=lower, upper=upper, order="hclust", insig="blank", tl.col="black", lower.col=col1(100), upper.col=col1(100), ...)
  dev.off()
}
```

### Read in the merged datasets, abbreviating year and month designators for compact graph display

```{r plotdata-corrs, include=TRUE, echo=TRUE}
yetwd(rRoot)
cnj02.merged.tb <- read_csv(pheno_dpath2fpath("MergedData/CNJ02_PlotData.csv")) %>%
                    mutate(year = gsub("20([0-9]{2})", "\\1", year)) %>% #Abbreviate the years for compact display of labels
                    rename_with(~ gsub("_", "", .x, fixed = TRUE), .cols=!c(accession_name)) %>%
                    rename_with(~ gsub("September", "Sep", .x, fixed = TRUE)) %>%
                    rename_with(~ gsub("October", "Oct", .x, fixed = TRUE))
cnj04.merged.tb <- read_csv(pheno_dpath2fpath("MergedData/CNJ04_PlotData.csv")) %>%
                    mutate(year = gsub("20([0-9]{2})", "\\1", year)) %>% #Abbreviate the years for compact display of labels
                    rename_with(~ gsub("_", "", .x, fixed = TRUE), .cols=!c(accession_name)) %>%
                    rename_with(~ gsub("September", "Sep", .x, fixed = TRUE)) %>%
                    rename_with(~ gsub("October", "Oct", .x, fixed = TRUE))
cnj02.merged.mmeans.tb <- read_csv(pheno_dpath2fpath("MergedData/CNJ02_PlotData.mmeans.csv")) %>%
                            mutate(year = gsub("20([0-9]{2})", "\\1", year)) #Abbreviate the years for compact display of labels
cnj04.merged.mmeans.tb <- read_csv(pheno_dpath2fpath("MergedData/CNJ04_PlotData.mmeans.csv")) %>%
                            mutate(year = gsub("20([0-9]{2})", "\\1", year)) #Abbreviate the years for compact display of labels





#cnj04_pdata.monthmeans.tb <- cnj04_pdata.tb %>% group_by(year, accession_name) %>% summarise(across(.cols=TY:PAC, mean)) %>% ungroup()
#cnj04_pdata.monthmeans.wider.tb <- pivot_wider(cnj04_pdata.monthmeans.tb, names_from=year, values_from=TY:PAC)
#cnj04_pdata.monthmeans.corr.tb <- cor(cnj04_pdata.monthmeans.wider.tb %>% select(!accession_name), use="pairwise.complete.obs")
#cnj04_pdata.means.tb <- cnj04_pdata.tb %>% group_by(accession_name) %>% summarise(across(.cols=TY:PAC, mean)) %>% ungroup()
#cnj04_pdata.means.corr.tb <- cor(cnj04_pdata.means.tb %>% select(!accession_name), use="pairwise.complete.obs")
```

### Generate Plots of Correlation Matrices Across All Traits, Across Years


```{r plotdata-corrs, include=TRUE, echo=TRUE}
setwd(rRoot)
cnj02.alltraits.pw.tb <- cnj02.merged.mmeans.tb %>% 
                                  pivot_longer(cols=BL:PAC, names_to='trait', values_to='value') %>% 
                                  pivot_wider(names_from=year, values_from=value)
gencorrplot(cnj02.alltraits.pw.tb %>% select(!c(accession_name, accession, row, column, trait)), filename=paste0(workflow,"/traits/plots/corrplot.cnj02.alltraits.png"), method="number", tl.pos= "d", cl.pos = "n")
View(cnj02.alltraits.pw.tb)

cnj04.alltraits.pw.tb <- cnj04.merged.mmeans.tb %>% 
                                  filter(year != '13') %>% #Filter out 2013, as data does not overlap with other datasets
                                  mutate(year = paste0("y",year)) %>%
                                  pivot_longer(cols=BL:PAC, names_to='trait', values_to='value') %>% 
                                  pivot_wider(names_from=year, values_from=value)
View(cnj04.alltraits.pw.tb)
setwd(rRoot)
gencorrplot(cnj04.alltraits.pw.tb %>% select(!c(accession_name, accession, row, column, trait)), filename=paste0(workflow,"/traits/plots/corrplot.cnj04.alltraits.png"), method="number", cl.pos = "n")
```
### Generate Correlation Matrices Across Months and Years

```{r include=TRUE, warning=FALSE, echo=FALSE}
setwd(rRoot)
cnj02.merged.wider.tb <- pivot_wider(cnj02.merged.tb, names_from=c(year), values_from=BL:PACOct, names_sep="")
gencorrplot(cnj02.merged.wider.tb %>% select(!c(accession_name, accession, row, column)), filename=paste0(workflow,"/traits/plots/corrplot.cnj02.ym.png"), width=2560, height=2048, tl.srt=45, tl.cex=2, cl.cex=2)

cnj04.merged.wider.tb <- pivot_wider(cnj04.merged.tb %>% filter(year != 13), names_from=c(year), values_from=BL:PACOct, names_sep="") #Filter out 2013 b/c it is only represented for parents of plot dataset -- no equivalent in other data
gencorrplot(cnj04.merged.wider.tb %>% select(!c(accession_name, accession, row, column)), filename=paste0(workflow,"/traits/plots/corrplot.cnj04.ym.png"), width=2560, height=2048, tl.srt=45, tl.cex=2, cl.cex=2)
```
### Generate Correlation Matrices Across Years

```{r include=TRUE, warning=FALSE, echo=FALSE}
setwd(rRoot)
cnj02.merged.mmeans.wider.tb <- pivot_wider(cnj02.merged.mmeans.tb, names_from=c(year), values_from=BL:PAC, names_sep="")
gencorrplot(cnj02.merged.mmeans.wider.tb %>% select(!c(accession_name, accession, row, column)), filename=paste0(workflow,"/traits/plots/corrplot.cnj02.y.png"), width=2048, height=2200, tl.srt=45, tl.cex=1.8, cl.cex=1.8)

cnj04.merged.mmeans.wider.tb <- cnj04.merged.mmeans.tb %>% 
                                filter(year != '13') %>%
                                pivot_wider(names_from=c(year), values_from=BL:PAC, names_sep="")
gencorrplot(cnj04.merged.mmeans.wider.tb %>% select(!c(accession_name, accession, row, column)), filename=paste0(workflow,"/traits/plots/corrplot.cnj04.y.png"), width=2048, height=2200, tl.srt=45, tl.cex=1.8, cl.cex=1.8)
```
### Generate Correlation Matrices With Traits Averaged Across Months and Years

```{r include=TRUE, warning=FALSE, echo=FALSE}
setwd(rRoot)

cnj02.merged.means.tb <- cnj02.merged.mmeans.tb %>%
                          group_by(accession_name, row, column) %>%
                          summarise(across(.cols=BL:PAC, mean)) %>%
                          ungroup()
gencorrplot.mixed(cnj02.merged.means.tb %>% select(!c(accession_name, row, column)), filename=paste0(workflow,"/traits/plots/corrplot.cnj02.png"), width=2048, height=2048, tl.cex=3, cl.cex=2, number.cex=2.5)

cnj04.merged.means.tb <- cnj04.merged.mmeans.tb %>%
                          group_by(accession_name, row, column) %>%
                          summarise(across(.cols=BL:PAC, mean)) %>%
                          ungroup()
gencorrplot.mixed(cnj04.merged.means.tb %>% select(!c(accession_name, row, column)), filename=paste0(workflow,"/traits/plots/corrplot.cnj04.png"), width=2048, height=2048, tl.cex=3, cl.cex=2, number.cex=2.5)
```

------------------------------------------------------------------------

## Assess trait distributions and plot trait correlations.

```{r plot-corrs}
setwd(rRoot);
source('qtl_pipeline_00_2_plotcors.R', echo=FALSE);
```

------------------------------------------------------------------------

## Fit Models

The following code fits models according to the specification in the folder Workflows/`r params$workflow`/, and then executes an drop-one ANOVA analysis to look for significance in effects.

```{r model-fit}
setwd(rRoot);
source('qtl_pipeline_01_genmodels.R', echo=FALSE);
```

```{r model-analyze, include=FALSE}
setwd(rRoot);
source('qtl_pipeline_01_analyzemodels.R', echo=FALSE);
```

------------------------------------------------------------------------

## Generate Plots Based on Models

```{r model-plots}
setwd(rRoot);
source('qtl_pipeline_01_03_genBLUPplots.R', echo=FALSE); 
```

------------------------------------------------------------------------

## Run Perms on HTCondor System

In order to calculate QTL LOD-score significance, permutations of the functions that execute QTL Mapping in the `r/QTL` package, `scanone()` and `scantwo()`, will be run on the UW Madison HTCondor System.

The steps needed to run these these permutations and pull that information off the HTCondor server are best executed by the `Makefile` defined in `Scripts/R/` folder.

### Build R Package Dependencies and Bundle in Tarball Archive

This is necessary to run the needed functionality on the HTCondor compute nodes. These dependencies are defined in the `HTCondorFiles/packagedeps.chtc.R` file. Variables such as `R_VERSION`, `USERNAME`, and `SUBMIT_SERVER` are configurable. The former is defined based the available R versions supported by the UW Madison HTCondor system (see online documentation), and the latter two must be specified based on the account username and submit server URL you are given when you register with UW Madison CHTC to use their high throughput compute system. `R_VERSION` is currently defined in ``` r workflow``/config/perms.mk ```.

    make RBuild

After the dependent packages been generated by an HTCondor node and placed in an archive, you can download the package dependency tarball by typing the following:

    make RDownload

*NOTE:* Use the `condor_q` script on the sumbit server, through an ssh terminal prompt, to query and see when the node is finished (and whether it finished successfully).

### Automatically Construct a Set of HTCondor Submit Scripts for 1D QTL Map Permutations

A python script is supplied in HTCondors/ file to construct the necessary contingent of HTCondor scripts needed to parcel out the permutations onto separate compute nodes of the HTCondor system. This is due to the fact that HTCondor requires explicitly definining the number of needed nodes.

Parameters that define the total number of permutations to run per model (`TOTAL_PERMS_PER_TRAIT`), and the number of compute nodes to distribute permutation computations across (`NUM_CLUSTERS_PER_TRAIT`), are defined in ``` r workflow``/config/perms.mk ```. Together, these `TOTAL_PERMS_PER_TRAIT/NUM_CLUSTERS_PER_TRAIT` define the number of permutations run on each independent compute node. `START_SEED` doesn't need to be changed, but helps generate some randomness to the permutation process. The seed used is saved in a file so that the results can be recapitulated.

    WORKFLOW=<WORKFLOW_FOLDER_HERE> make PermBuild

You could be prompted for your account password, and this will also copy the packaged HTCondor scripts, their parameters, and their necessary dependencies to teh submit node.

### Run the 1D QTL Map Permutations

    WORKFLOW=<WORKFLOW_FOLDER_HERE> make RunPerms

This could take some time to execute, depending on the available compute node resources. You can query the status of your submission through `condor_q` executable.

### Download 1D QTL Map Permutation Results and Merge into One Dataset

    WORKFLOW=<WORKFLOW_FOLDER_HERE> make PullPerms
    WORKFLOW=<WORKFLOW_FOLDER_HERE> make PermMerge

### Automatically Construct a Set of HTCondor Submit Scripts for 2D QTL Map Permutations

Just as in the 1D case, you will need to generate a list of HTCondor scripts to parcel out the 2D QTL mapping permutations on the compute nodes.

    WORKFLOW=<WORKFLOW_FOLDER_HERE> make Perm2DBuild

### Run the 2D QTL Map Permutations

    WORKFLOW=<WORKFLOW_FOLDER_HERE> make RunPerms2D

### Download 2D QTL Map Permutation Results and Merge into One Dataset

    WORKFLOW=<WORKFLOW_FOLDER_HERE> make PullPerms2D
    WORKFLOW=<WORKFLOW_FOLDER_HERE> make Perm2DMerge

After running the set of permutations and downloading/merging these, you shouldn't need to rerun these steps as long as you don't change the fitted model params for your traits. The merged permutation calculations will be available in an R binary data file format (rds extension), under the subfolder relevant to each trait in your workflow. The 1D permutations will be saved as an `operm.rds` file, and the 2D permutations will be saved as an `operm.2D.rds` files. These files will loaded by subsequent scripts to determine QTL significance.

------------------------------------------------------------------------

## Run the 1D QTL Scan

This code will call the `R/qtl:scanone()` function to execute a single-QTL scan through the genome. Parameters defining the regression method (i.e. Halley-Knot) and the significance levels are currently defined in your workflow folder under ``` r workflow``/config/model.cfg ```.

```{r qtl-1D}
setwd(rRoot);
source('qtl_pipeline_04_scanone.R', echo=FALSE); 
```

------------------------------------------------------------------------

## Run the Model Selection QTL Scan and Fit QTL

This code will call the `R/qtl:stepwiseqtl()` function to execute a single-QTL scan through the genome, and also call `R/qtl:fitqtl()` to fit found QTL.

```{r qtl-MQTL}
setwd(rRoot);
source('qtl_pipeline_07_stepwiseqtl.local.R', echo=FALSE); 
source('qtl_pipeline_08_makefitqtls.R', echo=FALSE); 
```

------------------------------------------------------------------------

## Collate QTL Results into One Table

All significant results will be collated into a single table and stored in a csv file in your selected workflow folder.

```{r qtl-collate}
setwd(rRoot);
source('qtl_pipeline_09_collate.R.local.R', echo=FALSE); 
```

------------------------------------------------------------------------

## Display QTL Table Results

```{r qtl-table}
setwd(rRoot);
num_top_qtl = 2; #Specifies the number of top QTL to return per trait
qtl_method = "scanone" #First display 'scanone' results
source('qtl_pipeline_10_01_genQTLtables.R', echo=FALSE); 
qtl_method = "stepwiseqtl" #Display 'stepwiseqtl' results
source('qtl_pipeline_10_01_genQTLtables.R', echo=FALSE); 
```

------------------------------------------------------------------------

## Generate Consensus QTL

This was something that Luis did, but essentially trait QTL within 5 cM of each other across model years are treated as equivalent.

```{r qtl-consensus}
setwd(rRoot);
source('qtl_pipeline_10_genconsensus.R', echo=FALSE);
```

------------------------------------------------------------------------

## Generate QTL Effect Plots/Tables

Calculate QTL effect sizes and generate effect plots/tables.

```{r qtl-effects}
setwd(rRoot);
source('qtl_pipeline_10_genconsensus.R', echo=FALSE);
```

------------------------------------------------------------------------

## Generate Circos Plots of Significant QTL

Generate the necessary files to display significant QTL found in circos plot format. Uses [Circos.js](https://github.com/nicgirault/circosJS) library as framework to generate interactive circos plots in javascript.

```{r qtl-circos}
setwd(rRoot);
source('qtl_pipeline_11_gencircos.R', echo=FALSE);
```

------------------------------------------------------------------------

## Launch Local HTTP Server to Render QTL Circos Plots

Copy the files needed to render the circos plots to a sandbox folder, defined in RMarkdown params as `r sandbox`. Launch a local http server to render/view the circos plots and interact with them.

*NOTE*: You will need to install the node package manager command-line utility, [npm](https://www.npmjs.com/), on your system before running this.

```{bash qtl-circos-render}
cd R/
make GenCircosSandbox
make LaunchCircosSandbox
```
